import streamlit as st
import joblib
import requests
import sys
import os
from dotenv import load_dotenv
from PIL import Image

# ğŸ›  Path setup
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
env_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".env"))
load_dotenv(dotenv_path=env_path)

API_URL = os.getenv("API_URL", "http://localhost:8000")

from utils.feature_engineering import extract_features

# ğŸŒ Streamlit Config
st.set_page_config(page_title="PhishAI - Advanced Phishing Detection", layout="centered")
st.title("ğŸ¯ PhishAI - Advanced Phishing Detection Platform")

st.markdown("""
Welcome to **PhishAI** ğŸ›¡  
A next-generation platform for analyzing suspicious links using:
- ğŸ” Final Verdict Powered by Whitelist + Threat Intelligence  
- ğŸ¤– AI Model Learns Silently Behind-the-Scenes  
- ğŸ§ª Secure Sandbox Execution & Behavior Capture  
""")

# ğŸ”— User Input
url = st.text_input("ğŸ”— Enter URL to Analyze")
message = st.text_area("ğŸ’¬ Optional Message or Email Body (text content)")

# â„¹ï¸ Tip
st.info("ğŸ’¡ **Tip**: Start with 'ğŸš¦ Full AI + Intel Scan'. Use 'ğŸ§¬ Deep Scan (Sandbox)' for suspicious links.")

col1, col2 = st.columns(2)

# ğŸš¦ AI + Intel Scan
with col1:
    if st.button("ğŸš¦ Full AI + Intel Scan"):
        if not url:
            st.warning("Please enter a URL to analyze.")
        else:
            with st.spinner("Running full analysis pipeline..."):
                try:
                    response = requests.post(f"{API_URL}/scan", json={"text": url, "message": message})
                    if response.status_code == 200:
                        result = response.json()
                        label = result.get("label", "unknown")
                        confidence = result.get("confidence", 0)
                        override = result.get("override")
                        vt = result.get("threat_intel", {}).get("VirusTotal", {})
                        haus = result.get("threat_intel", {}).get("URLhaus", {})

                        vt_safe = vt.get("malicious") is False
                        haus_safe = haus.get("listed") is False

                        st.subheader("ğŸ” Final Verdict")
                        if override == "whitelist":
                            st.success("âœ… BENIGN â€” Whitelist override applied (trusted domain).")
                        elif vt_safe and haus_safe:
                            st.success("âœ… BENIGN â€” Confirmed safe by Threat Intelligence.")
                        elif label == "phishing":
                            st.error("ğŸš¨ PHISHING DETECTED â€” AI flagged this as suspicious.")
                        else:
                            st.success("âœ… BENIGN â€” No threats or AI triggers found.")

                        with st.expander("ğŸ›¡ï¸ Threat Intelligence Layer"):
                            st.json({"VirusTotal": vt, "URLhaus": haus})

                        with st.expander("ğŸ“„ Raw API Response (Debug Panel)"):
                            st.json(result)
                    else:
                        st.error(f"API error {response.status_code}: {response.text}")
                except Exception as e:
                    st.error(f"ğŸš« Scan Error: {str(e)}")

# ğŸ§¬ Deep Sandbox Scan
with col2:
    if st.button("ğŸ§¬ Deep Scan (Sandbox)", help="Simulates behavior and captures JS/auto-downloads"):
        if not url:
            st.warning("Please enter a URL to sandbox.")
        else:
            with st.spinner("Running inside secure sandbox..."):
                try:
                    response = requests.post(f"{API_URL}/sandbox-check", json={"url": url})
                    if response.status_code == 200:
                        raw = response.json()

                        # Handle nested report
                        report = raw.get("sandbox_report", {})
                        if isinstance(report.get("sandbox_report"), dict):
                            report = report["sandbox_report"]

                        st.subheader("ğŸ”¬ Deep Scan Results â€” Behavioral Sandbox")

                        # ğŸ§  Heuristic Score
                        score = report.get("heuristic_score", 0)
                        st.info(f"ğŸ§  Heuristic Risk Score: **{score} / 10**", icon="ğŸ“Š")
                        with st.expander("â„¹ï¸ What is this?"):
                            st.markdown("""
**Heuristic Score** estimates phishing risk using:

- Suspicious JS behavior
- Phishing keywords
- Console errors
- Auto-download attempts
""")

                        # ğŸ–±ï¸ Mouse Interaction
                        if "Mouse movement & scroll simulation performed." in report.get("debug", []):
                            st.success("ğŸ–±ï¸ Simulated user interaction successful.")

                        # ğŸ“¸ Screenshot
                        screenshot_path = report.get("screenshot_path")
                        local_screenshot_path = os.path.join("sandbox/screenshots", os.path.basename(screenshot_path)) if screenshot_path else None

                        if local_screenshot_path and os.path.exists(local_screenshot_path):
                            st.image(Image.open(local_screenshot_path), caption="ğŸ“¸ Captured Screenshot", use_container_width=True)
                        elif local_screenshot_path:
                            st.image(local_screenshot_path, caption="ğŸ“¸ Captured Screenshot", use_container_width=True)
                        else:
                            st.info("No screenshot was captured.")

                        # ğŸ§¾ Categorized Console Logs
                        categorized = report.get("categorized_logs", {})
                        if categorized:
                            with st.expander("ğŸ–¥ï¸ Console Logs â€” Categorized"):
                                if categorized.get("errors"):
                                    st.error("ğŸš« **Errors**")
                                    for log in categorized["errors"]:
                                        st.code(log)
                                if categorized.get("warnings"):
                                    st.warning("âš ï¸ **Warnings**")
                                    for log in categorized["warnings"]:
                                        st.code(log)
                                if categorized.get("info"):
                                    st.info("â„¹ï¸ **Info Logs**")
                                    for log in categorized["info"]:
                                        st.code(log)
                                if categorized.get("other"):
                                    st.markdown("ğŸ” **Other Logs**")
                                    for log in categorized["other"]:
                                        st.code(log)
                        else:
                            st.info("No console logs captured.")

                        # ğŸš¨ Auto-download
                        if report.get("auto_download_detected"):
                            st.error("ğŸš¨ Auto-download attempt detected!")

                        # âš ï¸ Errors
                        if report.get("error"):
                            st.warning(f"âš ï¸ Sandbox Error: {report['error']}")

                        # ğŸ›  Raw
                        with st.expander("ğŸ“„ Raw Sandbox Response (Debug Panel)"):
                            st.json(report)
                    else:
                        st.error(f"ğŸš« Sandbox API Error {response.status_code}: {response.text}")
                except Exception as e:
                    st.error(f"ğŸš« Sandbox Connection Error: {str(e)}")

# Footer
st.markdown("""<hr style="height:1px;border:none;color:#ccc;background-color:#ccc;" /> """, unsafe_allow_html=True)
st.markdown("""
<div style="text-align: center; padding: 10px; font-size: 13px; color: gray;">
    PhishAI Â© 2025 | Developed by <strong>Gehad</strong> â€” Advanced Phishing Detection and Sandbox Analysis.
</div>
""", unsafe_allow_html=True)

